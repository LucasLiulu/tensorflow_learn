{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然语言处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse_softmax_cross_entropy_with_logits func loss:  [0.32656264 0.4643688 ]\n",
      "softmax_cross_entropy_with_logits func loss:  [0.32656264 0.4643688 ]\n",
      "second time with smooth,  softmax_cross_entropy_with_logits loss:  [0.37656265 0.48936883]\n"
     ]
    }
   ],
   "source": [
    "# NLP中常用的两个计算交叉熵的函数：\n",
    "# sparse_softmax_cross_entropy_with_logits和\n",
    "# softmax_cross_entropy_with_logits\n",
    "\n",
    "# NLP处理会先将词转换成整数\n",
    "word_labels = tf.constant([2, 0])\n",
    "# 假设模型对两个单词进行预测时，参数的logit分别为一下两个列表\n",
    "predict_logits = tf.constant([[2.0, -1.0, 3.0], [1.0, 0.0, -0.5]])\n",
    "# 如需计算概率，可用以下函数\n",
    "prob = tf.nn.softmax(predict_logits)\n",
    "loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=word_labels, logits=predict_logits)\n",
    "sess = tf.Session()\n",
    "print('sparse_softmax_cross_entropy_with_logits func loss: ', sess.run(loss))\n",
    "\n",
    "# 使用softmax_cross_entropy_with_logits计算损失时，要求待预测的目标要以概率分布的形式给出\n",
    "word_prob_distribution = tf.constant([[0.0, 0.0, 1.0], [1.0, 0.0, 0.0]])\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=word_prob_distribution, logits=predict_logits)\n",
    "print('softmax_cross_entropy_with_logits func loss: ', sess.run(loss))\n",
    "\n",
    "# 技巧：使用softmax_cross_entropy_with_logits时，将正确数据的概率设置成一个比1.0略小，将错误数据设置成比。0.0略大的值\n",
    "# 可避免过拟合\n",
    "word_prob_distribution_smooth = tf.constant([[0.01, 0.01, 0.98], [0.98, 0.01, 0.01]])\n",
    "loss = tf.nn.softmax_cross_entropy_with_logits_v2(labels=word_prob_distribution_smooth, logits=predict_logits)\n",
    "print('second time with smooth,  softmax_cross_entropy_with_logits loss: ', sess.run(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
