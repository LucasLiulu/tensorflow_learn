{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 第4章 深层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.eval of <tf.Tensor 'clip_by_value:0' shape=(2, 3) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "v = tf.constant([[1.0, 2.0, 3.0],[4.0, 5.0, 6.0]])\n",
    "print(tf.clip_by_value(v, 2.5, 4.5).eval)    # clip_by_value 将结果限制在2.5和4.5之间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.eval of <tf.Tensor 'Log_3:0' shape=(1, 3) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "v = tf.constant([[1.0, 2.0, 3.0]])\n",
    "print(tf.log(v).eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = tf.log(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.eval of <tf.Tensor 'Log_7:0' shape=(1, 3) dtype=float32>>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.6499996\n",
      "6.2125\n"
     ]
    }
   ],
   "source": [
    "# 带正则化的损失函数\n",
    "w = tf.constant([[1.0, -2.0], [3.2, 3.1]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.contrib.layers.l1_regularizer(.5)(w)))    # L1正则\n",
    "    print(sess.run(tf.contrib.layers.l2_regularizer(.5)(w)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n",
      "[4. 3. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "v1 = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "v2 = tf.constant([4.0, 3.0, 2.0, 1.0])\n",
    "sess = tf.InteractiveSession()\n",
    "print(tf.greater(v1, v2).eval())\n",
    "print(tf.where(tf.greater(v1, v2), v1, v2).eval())     # where函数根据第一个参数觉得选择输出大的那个，类似于c中的：？运算符。\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8113182]\n",
      " [ 1.4845988]]\n"
     ]
    }
   ],
   "source": [
    "# 使用自定义损失函数\n",
    "from numpy.random import RandomState\n",
    "batch_size = 8\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2), name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y_input')\n",
    "w1 = tf.Variable(tf.random_normal([2, 1], stddev=1, seed=1))\n",
    "y = tf.matmul(w1, x)\n",
    "loss_less = 10\n",
    "loss_more = 1\n",
    "loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y - y_) * loss_more, (y_ - y) * loss_less))    # 自定义损失函数\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "# 生成数据和标签\n",
    "rdm = RandomState(1)\n",
    "data_size = 128\n",
    "X = rdm.rand(data_size, 2)\n",
    "\n",
    "Y = [[X1+X2+rdm.rand()/10.0-0.05] for (X1, X2) in X]\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    steps = 1000\n",
    "    for i in range(steps):\n",
    "        start = (i * batch_size) % data_size\n",
    "        end = (i * batch_size) % data_size + batch_size\n",
    "        #print(X[start: end])\n",
    "        #print(Y[start: end])\n",
    "        #sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]})      # 为何会出错？\n",
    "    print (sess.run(w1))\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "7.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 指数衰减学习率：tf.train.exponential_decay\n",
    "# 正则化L1， L2\n",
    "w = tf.constant([[1.0, 2.0], [-3.0, 4.0]])\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tf.contrib.layers.l1_regularizer(.5)(w)))   # L1\n",
    "    print(sess.run(tf.contrib.layers.l2_regularizer(.5)(w)))   # L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_33:0' shape=(2, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_35:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_37:0' shape=(10, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_39:0' shape=(10, 1) dtype=float32_ref>\n",
      "Tensor(\"AddN_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 将变量加入到集合中，便于搭建深度网络\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_weight(shape, lambda0):\n",
    "    var = tf.Variable(tf.random_normal(shape), dtype=tf.float32)\n",
    "    # 将损失项加入集合，add_to_collection函数的第一个参数是集合的名称\n",
    "    tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda0)(var))\n",
    "    return var\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "batch_size = 8\n",
    "layer_dimension = [2, 10, 10, 10, 1]\n",
    "n_layers = len(layer_dimension)\n",
    "cur_layer = x\n",
    "in_demension = layer_dimension[0]\n",
    "\n",
    "# 创建5层神经网络。\n",
    "for i in range(1, n_layers):\n",
    "    out_demension = layer_dimension[i]   #出度，即这层网络的神经元与下一层网络相连的神经元个数。\n",
    "    w = get_weight([in_demension, out_demension], 1e-3) \n",
    "    print(w)\n",
    "    bias = tf.Variable(tf.constant(0.1, shape=[out_demension]))   # 偏置\n",
    "    cur_layer = tf.nn.relu(tf.matmul(cur_layer, w) + bias)   # 每层神经网络的输出\n",
    "    in_demension = layer_dimension[i]\n",
    "    \n",
    "mse_loss = tf.reduce_mean(tf.square(cur_layer - y_))    # 模型在训练集中的损失\n",
    "tf.add_to_collection('losses', mse_loss)\n",
    "\n",
    "# 从集合中获取所有的损失，将这些损失相加即为最终的损失\n",
    "loss = tf.add_n(tf.get_collection('losses'))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0]\n",
      "[5.0, 4.5]\n",
      "[10.0, 4.555]\n",
      "[10.0, 4.60945]\n"
     ]
    }
   ],
   "source": [
    "# 滑动平均模型\n",
    "# 它能使模型在测试集上的表现更健壮\n",
    "import tensorflow as tf\n",
    "v1 = tf.Variable(0, dtype=tf.float32)    # 定义一个用于计算滑动平均的变量，计算滑动平均的变量必须是实数！\n",
    "step = tf.Variable(0, trainable=False)\n",
    "ema = tf.train.ExponentialMovingAverage(0.99, step)\n",
    "maintrain_averages_op = ema.apply([v1])   # 意思是只给变量v1使用滑动平均\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    print(sess.run([v1, ema.average(v1)]))        # v1刚初始化后的值与其滑动平均值\n",
    "    \n",
    "    sess.run(tf.assign(v1, 5))     # 更新v1的值到5\n",
    "    sess.run(maintrain_averages_op)\n",
    "    print(sess.run([v1, ema.average(v1)]))   \n",
    "    \n",
    "    sess.run(tf.assign(step, 1000))\n",
    "    sess.run(tf.assign(v1, 10))\n",
    "    sess.run(maintrain_averages_op)\n",
    "    print(sess.run([v1, ema.average(v1)]))\n",
    "    \n",
    "    sess.run(maintrain_averages_op)\n",
    "    print(sess.run([v1, ema.average(v1)]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
