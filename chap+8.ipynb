{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 循环神经网络，主要基于LSTM模型实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_hidden_size)    # LSTM中使用的变量将会在此函数中被自动声明\n",
    "# 将LSTM的状态都初始化为0，zero_state函数将会输出两个张量，其中一个代表c，另一个代表h\n",
    "# batch_size是batch的大小\n",
    "state = lstm.zero_state(batch_size, tf.float32)\n",
    "# 损失函数\n",
    "loss = 0.0\n",
    "# num_steps 代表训练数据的长度，如果需要处理边长数据可以用dynamic_rnn\n",
    "for i in range(num_steps):\n",
    "    if i > 0 :\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    # lstm_output是当前LSTM的输出，它将用于其他层；\n",
    "    # state 是当前LSTM的状态，它将给下一时刻\n",
    "    lstm_output, state = lstm(current_input, state)\n",
    "    # 将当前时刻LSTM的输出传入一个全连接层得到最后的输出\n",
    "    final_output = fully_connected(lstm_output)\n",
    "    # 计算当前时刻输出的损失\n",
    "    loss += calc_loss(final_output, expected_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 深层循环nn，deep RNN\n",
    "# 它与cnn类似，每层循环体中的参数是一致的，不同层中的参数可以不同\n",
    "import tensorflow as tf\n",
    "# 先定义一个基本的LSTM结构作为循环体的基础结构\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell\n",
    "# MultiRNNCell类将实现深层循环神经网络中每一个时刻的前向传播过程\n",
    "# number_of_layers表示一个时刻对应的神经网络层数\n",
    "stacked_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm_cell(lstm_size) for _ in range(number_of_layers)])\n",
    "state = stacked_lstm.zero_state(batch_size, tf.float32)    # 初始状态\n",
    "# num_steps 代表训练数据的长度\n",
    "for i in range(num_steps):\n",
    "    if i > 0:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    # lstm_output是当前LSTM的输出，它将用于其他层；\n",
    "    # state 是当前LSTM的状态，它将给下一时刻\n",
    "    stacked_lstm_output, state = stacked_lstm(current_input, state)    \n",
    "    final_output = fully_connected(stacked_lstm_output)\n",
    "    loss += calc_loss(final_output, expected_output)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "循环神经网络的dropout\n",
    "循环神经网络中，只在同一时刻的不同层间进行状态的dropout，例如都是t时刻的层；\n",
    "而不同时刻不适用dropout，例如t时刻到t+1时刻的不进行dropout\n",
    "适用DropoutWrapper实现dropout\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell\n",
    "# DropoutWrapper实现dropout\n",
    "# 参数有两个：\n",
    "# 1）input_keep_prob控制输入的dropout概率；\n",
    "# 2）output_keep_prob控制输出的dropout概率\n",
    "stacked_lstm = rnn_cell.MultiRNNCell([tf.nn.rnn_cell.DropoutWrapper(lstm_cell(lstm_size)) for _ in range(number_of_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 以上是循环神经网络的基本知识，预测sin函数的代码之后实现。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
